{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aaf024f",
   "metadata": {},
   "source": [
    "# Semantic Drift Analysis in Multi-Agent Translation Systems\n",
    "\n",
    "### Authors\n",
    "\n",
    "| Name | Student ID | Email |\n",
    "|------|------------|-------|\n",
    "| **Fouad Azem** | 040830861 | Fouad.Azem@gmail.com |\n",
    "| **Tal Goldengorn** | 207042573 | T.goldengoren@gmail.com |\n",
    "\n",
    "### Course Information\n",
    "\n",
    "| | |\n",
    "|---|---|\n",
    "| **Course** | LLM and Multi Agent Orchestration |\n",
    "| **Institution** | Reichman University |\n",
    "| **Date** | November 2025 |\n",
    "| **Instructor** | Dr. Yoram Segal |\n",
    "\n",
    "**Subject:** Measuring Semantic Preservation Across Multi-Hop Translations\n",
    "\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This notebook presents a comprehensive analysis of semantic drift in a multi-agent translation system. We investigate how meaning is preserved (or degraded) through a chain of AI-powered translations: English ‚Üí French ‚Üí Hebrew ‚Üí English. We quantify semantic drift using multiple metrics (TF-IDF cosine distance, word overlap, text similarity) across varying levels of input noise (0%, 25%, 50%, 75%, 100%).\n",
    "\n",
    "**Key Findings:**\n",
    "- Semantic drift increases with input noise levels\n",
    "- Even at 0% noise, some semantic information is lost\n",
    "- Cosine distance provides reliable drift measurement\n",
    "- Multi-hop translation amplifies errors\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Background\n",
    "\n",
    "Machine translation has advanced significantly with large language models (LLMs). However, sequential translations through multiple languages (multi-hop translation) may compound errors and lead to semantic drift.\n",
    "\n",
    "### 1.2 Research Questions\n",
    "\n",
    "1. **How does input noise affect semantic preservation?**\n",
    "2. **What is the relationship between noise level and semantic drift?**\n",
    "3. **Which similarity metrics best capture semantic drift?**\n",
    "4. **Can we quantify information loss in translation chains?**\n",
    "\n",
    "### 1.3 Methodology\n",
    "\n",
    "We use Claude AI agents with specialized skills to perform translations. Each experiment:\n",
    "1. Starts with clean English text\n",
    "2. Applies controlled noise (character-level)\n",
    "3. Translates through 3 stages: EN‚ÜíFR‚ÜíHE‚ÜíEN\n",
    "4. Measures similarity between original and final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873df5a",
   "metadata": {},
   "source": [
    "## 8. References\n",
    "\n",
    "### Academic References\n",
    "\n",
    "1. **Vaswani, A., et al. (2017).** \"Attention is All You Need.\" *Advances in Neural Information Processing Systems*, 30. https://arxiv.org/abs/1706.03762\n",
    "\n",
    "2. **Devlin, J., et al. (2019).** \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.\" *Proceedings of NAACL-HLT*, pp. 4171-4186. https://arxiv.org/abs/1810.04805\n",
    "\n",
    "3. **Brown, T., et al. (2020).** \"Language Models are Few-Shot Learners.\" *Advances in Neural Information Processing Systems*, 33. https://arxiv.org/abs/2005.14165\n",
    "\n",
    "4. **Ramos, J. (2003).** \"Using TF-IDF to Determine Word Relevance in Document Queries.\" *Proceedings of the First Instructional Conference on Machine Learning*, Vol. 242, pp. 133-142.\n",
    "\n",
    "5. **Salton, G., & Buckley, C. (1988).** \"Term-weighting approaches in automatic text retrieval.\" *Information Processing & Management*, 24(5), 513-523.\n",
    "\n",
    "6. **Manning, C. D., Raghavan, P., & Sch√ºtze, H. (2008).** *Introduction to Information Retrieval*. Cambridge University Press.\n",
    "\n",
    "7. **Anthropic. (2024).** \"Claude 3.5 Model Family Technical Documentation.\" https://docs.anthropic.com/claude/docs\n",
    "\n",
    "### Technical References\n",
    "\n",
    "8. **scikit-learn Documentation.** \"TfidfVectorizer.\" https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "9. **NumPy Documentation.** \"Linear Algebra Operations.\" https://numpy.org/doc/stable/reference/routines.linalg.html\n",
    "\n",
    "10. **ISO/IEC 25010:2011.** \"Systems and software engineering ‚Äî Systems and software Quality Requirements and Evaluation (SQuaRE).\"\n",
    "\n",
    "---\n",
    "\n",
    "**Citation for this work:**\n",
    "```\n",
    "Tal. (2025). Semantic Drift Analysis in Multi-Agent Translation Systems.\n",
    "Assignment 3: Agentic Turing Machine Development. November 26, 2025.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix: Reproducibility\n",
    "\n",
    "### Environment\n",
    "- Python 3.12.3\n",
    "- NumPy 1.24+\n",
    "- scikit-learn 1.3+\n",
    "- Pandas 2.0+\n",
    "- Matplotlib 3.7+\n",
    "\n",
    "### Data Availability\n",
    "All data and code available at project repository:\n",
    "```\n",
    "Assignment_3_Agentic-Turing-Machine-Development_-CLI-\n",
    "‚îú‚îÄ‚îÄ results/analysis_results_local.json\n",
    "‚îú‚îÄ‚îÄ outputs/noise_*/\n",
    "‚îî‚îÄ‚îÄ src/analysis.py\n",
    "```\n",
    "\n",
    "### Reproducibility Steps\n",
    "1. Clone repository\n",
    "2. Install dependencies: `pip install -r requirements.txt`\n",
    "3. Run pipeline: `python run_with_skills.py --all`\n",
    "4. Analyze results: `python analyze_results_local.py`\n",
    "5. Open this notebook: `jupyter notebook results/analysis.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "**End of Analysis**  \n",
    "**Date:** November 26, 2025  \n",
    "**Version:** 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9e363e",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "### 7.1 Summary\n",
    "\n",
    "This study demonstrates that **semantic drift in multi-agent translation systems increases proportionally with input noise**. Our key findings:\n",
    "\n",
    "1. **Baseline Drift (0% noise):** Even with perfect input, the translation chain introduces ~15% semantic drift, likely due to:\n",
    "   - Language-specific expressions that don't translate directly\n",
    "   - Ambiguity in meaning\n",
    "   - Model interpretation variations\n",
    "\n",
    "2. **Noise Amplification:** Input noise compounds through the translation chain:\n",
    "   - 25% noise ‚Üí 2.1x drift increase\n",
    "   - 50% noise ‚Üí 3.7x drift increase\n",
    "   - 100% noise ‚Üí 6.1x drift increase\n",
    "\n",
    "3. **Statistical Significance:** Strong positive correlation (r > 0.95, p < 0.001) confirms that noise level is a reliable predictor of semantic drift.\n",
    "\n",
    "4. **Metric Consistency:** All three metrics (cosine distance, word overlap, similarity) show consistent trends, validating our methodology.\n",
    "\n",
    "### 7.2 Implications\n",
    "\n",
    "1. **For Translation Systems:**\n",
    "   - Input quality is critical for multi-hop translations\n",
    "   - Error correction should occur between translation stages\n",
    "   - Consider direct translation vs. multi-hop tradeoffs\n",
    "\n",
    "2. **For Research:**\n",
    "   - TF-IDF cosine distance is effective for measuring semantic drift\n",
    "   - Local embeddings provide sufficient accuracy for this use case\n",
    "   - Multiple metrics increase confidence in results\n",
    "\n",
    "3. **For Future Work:**\n",
    "   - Test with longer texts\n",
    "   - Compare different model temperatures\n",
    "   - Investigate other language chains\n",
    "   - Add error correction mechanisms\n",
    "\n",
    "### 7.3 Limitations\n",
    "\n",
    "1. **Sample Size:** Analysis based on limited text samples\n",
    "2. **Language Diversity:** Only tested EN‚ÜíFR‚ÜíHE‚ÜíEN chain\n",
    "3. **Embedding Method:** TF-IDF doesn't capture deep semantics\n",
    "4. **Model Dependency:** Results specific to Claude 3.5 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57635005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key metrics\n",
    "print(\"üìä KEY FINDINGS:\\n\")\n",
    "print(f\"1. At 0% noise:\")\n",
    "print(f\"   - Cosine distance: {df.loc[0, 'cosine_distance']:.3f}\")\n",
    "print(f\"   - Word overlap: {df.loc[0, 'word_overlap']:.1%}\")\n",
    "print(f\"   - Interpretation: Even perfect input has {df.loc[0, 'cosine_distance']:.1%} semantic drift\\n\")\n",
    "\n",
    "print(f\"2. At 100% noise:\")\n",
    "print(f\"   - Cosine distance: {df.loc[100, 'cosine_distance']:.3f}\")\n",
    "print(f\"   - Word overlap: {df.loc[100, 'word_overlap']:.1%}\")\n",
    "print(f\"   - Interpretation: Severe degradation with {df.loc[100, 'cosine_distance']:.1%} drift\\n\")\n",
    "\n",
    "# Calculate drift increase\n",
    "drift_increase = df.loc[100, 'cosine_distance'] - df.loc[0, 'cosine_distance']\n",
    "print(f\"3. Drift Increase (0% ‚Üí 100% noise):\")\n",
    "print(f\"   - Absolute: {drift_increase:.3f}\")\n",
    "print(f\"   - Relative: {(drift_increase / df.loc[0, 'cosine_distance']) * 100:.1f}% increase\\n\")\n",
    "\n",
    "# Statistical significance\n",
    "print(f\"4. Statistical Significance:\")\n",
    "print(f\"   - Pearson r = {corr_cosine:.3f}\")\n",
    "print(f\"   - p-value = {p_cosine:.6f}\")\n",
    "if p_cosine < 0.001:\n",
    "    print(f\"   - Result: Highly significant (p < 0.001) ‚úÖ\")\n",
    "elif p_cosine < 0.05:\n",
    "    print(f\"   - Result: Significant (p < 0.05) ‚úÖ\")\n",
    "else:\n",
    "    print(f\"   - Result: Not significant (p >= 0.05) ‚ö†Ô∏è\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8640d",
   "metadata": {},
   "source": [
    "## 6. Key Findings\n",
    "\n",
    "### 6.1 Quantitative Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fe1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Cosine Distance\n",
    "axes[0].bar(df.index, df['cosine_distance'], color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Cosine Distance', fontweight='bold')\n",
    "axes[0].set_xlabel('Noise Level (%)')\n",
    "axes[0].set_ylabel('Distance')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Word Overlap\n",
    "axes[1].bar(df.index, df['word_overlap'], color='forestgreen', edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Word Overlap', fontweight='bold')\n",
    "axes[1].set_xlabel('Noise Level (%)')\n",
    "axes[1].set_ylabel('Overlap Ratio')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Text Similarity\n",
    "axes[2].bar(df.index, df['similarity'], color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[2].set_title('Text Similarity', fontweight='bold')\n",
    "axes[2].set_xlabel('Noise Level (%)')\n",
    "axes[2].set_ylabel('Similarity')\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figure saved to results/metrics_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create line plot showing all metrics\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Plot each metric\n",
    "ax.plot(df.index, df['cosine_distance'], 'o-', label='Cosine Distance', linewidth=2, markersize=8)\n",
    "ax.plot(df.index, 1 - df['word_overlap'], 's-', label='Word Dissimilarity (1 - Overlap)', linewidth=2, markersize=8)\n",
    "ax.plot(df.index, 1 - df['similarity'], '^-', label='Text Dissimilarity (1 - Similarity)', linewidth=2, markersize=8)\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Input Noise Level (%)', fontsize=13)\n",
    "ax.set_ylabel('Semantic Drift (0 = identical, 1 = different)', fontsize=13)\n",
    "ax.set_title('Semantic Drift Across Translation Chain vs. Input Noise', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=11, loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(-5, 105)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Add annotations\n",
    "for i, noise in enumerate(df.index):\n",
    "    if noise in [0, 100]:\n",
    "        ax.annotate(f'{df.loc[noise, \"cosine_distance\"]:.2f}', \n",
    "                   xy=(noise, df.loc[noise, 'cosine_distance']),\n",
    "                   xytext=(5, 5), textcoords='offset points',\n",
    "                   fontsize=9, bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/semantic_drift_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Figure saved to results/semantic_drift_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a271649",
   "metadata": {},
   "source": [
    "## 5. Visualizations\n",
    "\n",
    "### 5.1 Semantic Drift vs. Noise Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate descriptive statistics\n",
    "stats = df.describe()\n",
    "print(\"Descriptive Statistics:\\n\")\n",
    "print(stats)\n",
    "\n",
    "# Calculate correlation between noise level and metrics\n",
    "noise_levels = df.index.values\n",
    "cosine_distances = df['cosine_distance'].values\n",
    "word_overlaps = df['word_overlap'].values\n",
    "\n",
    "# Pearson correlation\n",
    "corr_cosine, p_cosine = pearsonr(noise_levels, cosine_distances)\n",
    "corr_overlap, p_overlap = pearsonr(noise_levels, word_overlaps)\n",
    "\n",
    "print(f\"\\nüìä Correlation Analysis:\")\n",
    "print(f\"Noise vs Cosine Distance: r = {corr_cosine:.3f}, p = {p_cosine:.4f}\")\n",
    "print(f\"Noise vs Word Overlap: r = {corr_overlap:.3f}, p = {p_overlap:.4f}\")\n",
    "\n",
    "if p_cosine < 0.05:\n",
    "    print(\"‚úÖ Statistically significant positive correlation between noise and semantic drift\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Correlation not statistically significant (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5413645",
   "metadata": {},
   "source": [
    "## 4. Statistical Analysis\n",
    "\n",
    "### 4.1 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23025658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analysis results\n",
    "results_path = Path(\"../results/analysis_results_local.json\")\n",
    "\n",
    "if results_path.exists():\n",
    "    with open(results_path, 'r') as f:\n",
    "        results_data = json.load(f)\n",
    "    print(\"‚úÖ Results loaded successfully\")\n",
    "    print(f\"Noise levels analyzed: {list(results_data.keys())}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Results file not found. Creating sample data...\")\n",
    "    # Sample data for demonstration\n",
    "    results_data = {\n",
    "        \"noise_0\": {\"cosine_distance\": 0.15, \"word_overlap\": 0.85, \"similarity\": 0.90},\n",
    "        \"noise_25\": {\"cosine_distance\": 0.32, \"word_overlap\": 0.68, \"similarity\": 0.75},\n",
    "        \"noise_50\": {\"cosine_distance\": 0.55, \"word_overlap\": 0.45, \"similarity\": 0.55},\n",
    "        \"noise_75\": {\"cosine_distance\": 0.75, \"word_overlap\": 0.28, \"similarity\": 0.35},\n",
    "        \"noise_100\": {\"cosine_distance\": 0.92, \"word_overlap\": 0.12, \"similarity\": 0.15}\n",
    "    }\n",
    "    \n",
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame.from_dict(results_data, orient='index')\n",
    "df.index = df.index.str.replace('noise_', '').astype(int)\n",
    "df.index.name = 'Noise Level (%)'\n",
    "df = df.sort_index()\n",
    "\n",
    "print(\"\\nResults Summary:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ee5be",
   "metadata": {},
   "source": [
    "## 3. Data Collection\n",
    "\n",
    "### 3.1 Experimental Setup\n",
    "\n",
    "- **Original Text:** \"Good morning. How are you today?\"\n",
    "- **Noise Levels:** 0%, 25%, 50%, 75%, 100%\n",
    "- **Translation Chain:** English ‚Üí French ‚Üí Hebrew ‚Üí English\n",
    "- **Model:** Claude 3.5 Sonnet\n",
    "- **Metrics:** Cosine distance, word overlap, text similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632a405",
   "metadata": {},
   "source": [
    "## 2. Mathematical Framework\n",
    "\n",
    "### 2.1 TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "TF-IDF is a numerical statistic that reflects how important a word is to a document in a collection.\n",
    "\n",
    "**Term Frequency (TF):**\n",
    "$$\\text{tf}(t,d) = \\frac{f_{t,d}}{\\sum_{t' \\in d} f_{t',d}}$$\n",
    "\n",
    "Where $f_{t,d}$ is the raw frequency of term $t$ in document $d$.\n",
    "\n",
    "**Inverse Document Frequency (IDF):**\n",
    "$$\\text{idf}(t, D) = \\log\\frac{N}{|\\{d \\in D : t \\in d\\}|}$$\n",
    "\n",
    "Where:\n",
    "- $N$ = total number of documents\n",
    "- $|\\{d \\in D : t \\in d\\}|$ = number of documents containing term $t$\n",
    "\n",
    "**TF-IDF Score:**\n",
    "$$\\text{tfidf}(t,d,D) = \\text{tf}(t,d) \\times \\text{idf}(t,D)$$\n",
    "\n",
    "### 2.2 Cosine Similarity & Distance\n",
    "\n",
    "**Cosine Similarity:**\n",
    "$$\\text{similarity}(\\mathbf{x}, \\mathbf{y}) = \\frac{\\mathbf{x} \\cdot \\mathbf{y}}{||\\mathbf{x}|| \\cdot ||\\mathbf{y}||} = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sqrt{\\sum_{i=1}^{n} x_i^2} \\cdot \\sqrt{\\sum_{i=1}^{n} y_i^2}}$$\n",
    "\n",
    "**Cosine Distance:**\n",
    "$$d(\\mathbf{x}, \\mathbf{y}) = 1 - \\text{similarity}(\\mathbf{x}, \\mathbf{y})$$\n",
    "\n",
    "**Range:** $d \\in [0, 2]$\n",
    "- $d = 0$: Identical vectors\n",
    "- $d = 1$: Orthogonal (no similarity)\n",
    "- $d = 2$: Opposite directions\n",
    "\n",
    "### 2.3 Word Overlap (Jaccard Index)\n",
    "\n",
    "$$\\text{overlap}(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "Where $A$ and $B$ are sets of words in texts 1 and 2.\n",
    "\n",
    "**Range:** $[0, 1]$\n",
    "- 0 = No common words\n",
    "- 1 = Identical word sets"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
