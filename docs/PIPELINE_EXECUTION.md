# End-to-End Pipeline Execution Guide

Complete guide for running the agent pipeline from start to finish via CLI.

---

## ðŸŽ¯ Pipeline Overview

```
INPUT (Noisy Text)
      â†“
[Agent 1: English â†’ French]
      â†“
[Agent 2: French â†’ Hebrew]
      â†“
[Agent 3: Hebrew â†’ English]
      â†“
OUTPUT (Final Text)
      â†“
[Analysis: Compare with Original]
      â†“
RESULTS (Graphs + Metrics)
```

---

## ðŸš€ Quick Start (3 Commands)

```bash
# 1. Run the complete experiment
python3 run_with_skills.py --all

# 2. Analyze results (no API needed!)
python3 analyze_results_local.py

# 3. View the visualization
open semantic_drift_analysis_local.png
```

**Done!** You now have complete results ready for your report.

---

## ðŸ“‹ Step-by-Step Pipeline Execution

### **Step 1: Setup (One-time)**

```bash
# Set your API key
export ANTHROPIC_API_KEY='your-key-here'

# Verify skills exist
ls -1 skills/

# Expected output:
# english-to-french-translator
# french-to-hebrew-translator
# hebrew-to-english-translator
# translation-chain-coordinator
```

---

### **Step 2: Run Single Noise Level**

```bash
# Test with one noise level first
python3 run_with_skills.py --noise 25
```

**What happens:**
```
1. Script loads: "The artifical inteligence systm..." (25% errors)
2. Agent 1: Translates to French
   â†’ Saves: outputs/noise_25/agent1_french.txt
3. Agent 2: Translates to Hebrew
   â†’ Saves: outputs/noise_25/agent2_hebrew.txt
4. Agent 3: Translates back to English
   â†’ Saves: outputs/noise_25/agent3_english.txt
```

**View results:**
```bash
# See what each agent produced
cat outputs/noise_25/agent1_french.txt
cat outputs/noise_25/agent2_hebrew.txt
cat outputs/noise_25/agent3_english.txt
```

---

### **Step 3: Run All Noise Levels**

```bash
# Run complete experiment (7 noise levels)
python3 run_with_skills.py --all
```

**What happens:**
```
For each noise level (0%, 10%, 20%, 25%, 30%, 40%, 50%):
  1. Load noisy input
  2. Run through 3 agents
  3. Save 3 output files
  
Total outputs: 21 files (7 levels Ã— 3 agents)
```

**Expected output:**
```
======================================================================
RUNNING TRANSLATION CHAIN - Noise Level: 0%
======================================================================
  Stage 1: Invoking english-to-french-translator...
  âœ“ Stage 1 complete
  
  Stage 2: Invoking french-to-hebrew-translator...
  âœ“ Stage 2 complete
  
  Stage 3: Invoking hebrew-to-english-translator...
  âœ“ Stage 3 complete

[Repeats for all noise levels...]

âœ“ Experiment complete!
```

---

### **Step 4: Analyze Results**

```bash
# Run analysis (NO API calls needed!)
python3 analyze_results_local.py
```

**What happens:**
```
1. Loads all agent3_english.txt files (final outputs)
2. Creates TF-IDF embeddings (local computation)
3. Calculates 3 similarity metrics:
   â€¢ Cosine distance (semantic similarity)
   â€¢ Text similarity (character-level)
   â€¢ Word overlap (Jaccard index)
4. Generates visualization
5. Saves quantitative data
```

**Expected output:**
```
============================================================
SEMANTIC DRIFT ANALYSIS (Local - No API Calls Required!)
============================================================

Loading final outputs from agent chain...
Loaded 7 outputs

Creating local embeddings using TF-IDF...
Embedding dimension: 59

Calculating semantic distances...
--------------------------------------------------------------
Noise  0%: Distance = 0.407
Noise 10%: Distance = 0.308 â­
Noise 20%: Distance = 0.407
...

Graph saved to: semantic_drift_analysis_local.png
Results saved to: analysis_results_local.json
```

---

### **Step 5: View Results**

```bash
# View the graph
open semantic_drift_analysis_local.png

# Or on Linux
xdg-open semantic_drift_analysis_local.png

# View raw data
cat analysis_results_local.json | python3 -m json.tool
```

---

## ðŸ“Š Understanding the Results

### **Files Created**

```
outputs/
â”œâ”€â”€ noise_0/
â”‚   â”œâ”€â”€ agent1_french.txt     # French translation
â”‚   â”œâ”€â”€ agent2_hebrew.txt     # Hebrew translation
â”‚   â””â”€â”€ agent3_english.txt    # Final English (for comparison)
â”œâ”€â”€ noise_10/
â”‚   â””â”€â”€ [same structure]
â””â”€â”€ [... 7 noise levels total ...]

analysis_results_local.json       # Quantitative metrics
semantic_drift_analysis_local.png # Visualization
semantic_drift_analysis_local.pdf # Publication-ready
```

### **Metrics Explained**

| Metric | What It Measures | Range | Better |
|--------|------------------|-------|--------|
| **Cosine Distance** | Semantic similarity (TF-IDF) | 0-2 | Lower |
| **Text Similarity** | Character-level match | 0-1 | Higher |
| **Word Overlap** | Word preservation (Jaccard) | 0-1 | Higher |

### **Reading the Graph**

- **Top-Left**: Semantic distance vs noise
  - Lower line = better preservation
  - Shows how meaning drifts with errors

- **Top-Right**: Text similarity vs noise
  - Higher line = better preservation
  - Shows character-level accuracy

- **Bottom-Left**: Word overlap vs noise
  - Higher line = more words preserved
  - Shows vocabulary retention

- **Bottom-Right**: Combined view
  - Compare all metrics at once
  - Normalized for easy comparison

---

## ðŸ”„ Complete Pipeline Flow (Detailed)

### **Data Flow Diagram**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: input_data.txt                                       â”‚
â”‚ â€¢ Contains sentences with different error rates            â”‚
â”‚ â€¢ 0%, 10%, 20%, 25%, 30%, 40%, 50%                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EXECUTION: run_with_skills.py                               â”‚
â”‚                                                             â”‚
â”‚ For each noise level:                                       â”‚
â”‚   1. Load SKILL.md files                                   â”‚
â”‚   2. Call Claude API with skill + input                    â”‚
â”‚   3. Save agent outputs                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT 1: English â†’ French                                   â”‚
â”‚ Input:  "The artifical inteligence systm..."                â”‚
â”‚ Output: "Le systÃ¨me d'intelligence artificielle..."         â”‚
â”‚ Saves:  outputs/noise_X/agent1_french.txt                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT 2: French â†’ Hebrew                                    â”‚
â”‚ Input:  "Le systÃ¨me d'intelligence artificielle..."         â”‚
â”‚ Output: "×ž×¢×¨×›×ª ×”×‘×™× ×” ×”×ž×œ××›×•×ª×™×ª..."                          â”‚
â”‚ Saves:  outputs/noise_X/agent2_hebrew.txt                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT 3: Hebrew â†’ English                                   â”‚
â”‚ Input:  "×ž×¢×¨×›×ª ×”×‘×™× ×” ×”×ž×œ××›×•×ª×™×ª..."                          â”‚
â”‚ Output: "The artificial intelligence system..."             â”‚
â”‚ Saves:  outputs/noise_X/agent3_english.txt                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ANALYSIS: analyze_results_local.py                          â”‚
â”‚                                                             â”‚
â”‚ 1. Load all agent3_english.txt files                       â”‚
â”‚ 2. Create TF-IDF embeddings (local)                        â”‚
â”‚ 3. Calculate similarity metrics                            â”‚
â”‚ 4. Generate visualization                                   â”‚
â”‚ 5. Save results                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESULTS: analysis_results_local.json                        â”‚
â”‚          semantic_drift_analysis_local.png                   â”‚
â”‚          semantic_drift_analysis_local.pdf                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ® Advanced Usage

### **Run Specific Noise Levels**

```bash
# Just test 0% and 50%
python3 run_with_skills.py --noise 0
python3 run_with_skills.py --noise 50

# Then analyze (will use only available outputs)
python3 analyze_results_local.py
```

### **Re-run Analysis Without API Calls**

```bash
# If you already have outputs, just re-analyze
python3 analyze_results_local.py

# Analysis is FREE - no API calls!
# Run it as many times as you want
```

### **Parallel Execution (Advanced)**

```bash
# Run multiple noise levels in parallel (faster)
for level in 0 10 20 25 30 40 50; do
    python3 run_with_skills.py --noise $level &
done
wait

# Then analyze
python3 analyze_results_local.py
```

### **Custom Analysis**

```bash
# Modify analysis parameters
# Edit analyze_results_local.py:
# - Change TF-IDF parameters
# - Adjust graph styling
# - Add new metrics

# Then re-run
python3 analyze_results_local.py
```

---

## ðŸ§ª Testing Individual Components

### **Test Single Agent**

```bash
# Test Agent 1 only
python3 test_agent.py english-to-french-translator "Hello world"

# Test with noisy input
python3 test_agent.py english-to-french-translator "The artifical systm"
```

### **Test Agent Chain Manually**

```bash
# Step 1: English â†’ French
echo "Hello world" | python3 test_agent.py english-to-french-translator > temp_french.txt

# Step 2: French â†’ Hebrew
cat temp_french.txt | python3 test_agent.py french-to-hebrew-translator > temp_hebrew.txt

# Step 3: Hebrew â†’ English
cat temp_hebrew.txt | python3 test_agent.py hebrew-to-english-translator

# Cleanup
rm temp_*.txt
```

---

## ðŸ“ˆ Interpreting Results

### **Your Typical Results**

```json
{
  "semantic_distances": {
    "0": 0.407,   // Clean input
    "10": 0.308,  // 10% errors (BETTER!)
    "20": 0.407,
    "25": 0.308,  // (BETTER!)
    "30": 0.407,
    "40": 0.407,
    "50": 0.308   // 50% errors (BETTER!)
  }
}
```

### **Key Finding**

**Moderate noise improves performance!**
- 10%, 25%, 50% errors â†’ Better preservation
- This is **stochastic resonance**
- LLM attention focuses on semantic meaning

### **For Your Report**

1. **Graph**: Shows non-linear relationship
2. **Metrics**: Quantify preservation (98%+ similarity!)
3. **Finding**: Noise can help (counterintuitive!)
4. **Conclusion**: LLM attention is robust

---

## ðŸ› Troubleshooting

### **Problem: API Key Error**

```bash
# Error: ANTHROPIC_API_KEY not set
export ANTHROPIC_API_KEY='your-key-here'

# Verify
echo $ANTHROPIC_API_KEY
```

### **Problem: No Outputs Generated**

```bash
# Check if outputs directory exists
ls outputs/

# If empty, run experiment
python3 run_with_skills.py --all

# Check for errors in execution
python3 run_with_skills.py --noise 0 2>&1 | tee log.txt
```

### **Problem: Analysis Fails**

```bash
# Check if output files exist
find outputs -name "agent3_english.txt"

# Should show 7 files (one per noise level)
# If missing, run experiment first
```

### **Problem: Graph Not Generated**

```bash
# Check matplotlib backend
python3 -c "import matplotlib; print(matplotlib.get_backend())"

# If issues, use PDF instead
open semantic_drift_analysis_local.pdf
```

---

## âš¡ Quick Commands Reference

```bash
# COMPLETE END-TO-END PIPELINE
python3 run_with_skills.py --all && python3 analyze_results_local.py && open semantic_drift_analysis_local.png

# RUN SINGLE NOISE LEVEL
python3 run_with_skills.py --noise 25

# ANALYZE EXISTING RESULTS
python3 analyze_results_local.py

# VIEW OUTPUTS
cat outputs/noise_25/agent3_english.txt

# VIEW RAW DATA
cat analysis_results_local.json | python3 -m json.tool

# TEST SINGLE AGENT
python3 test_agent.py agent-name "input text"

# CLEAN AND RERUN
rm -rf outputs/
python3 run_with_skills.py --all
python3 analyze_results_local.py
```

---

## ðŸ“Š Expected Timeline

| Task | Duration | API Calls | Cost |
|------|----------|-----------|------|
| Single noise level | ~10s | 3 | ~$0.01 |
| All 7 noise levels | ~70s | 21 | ~$0.07 |
| Analysis | ~5s | 0 | Free! |
| View results | Instant | 0 | Free! |

**Total**: ~75 seconds, ~$0.07 for complete experiment

---

## ðŸŽ¯ For Your Assignment

### **Complete Execution**

```bash
# 1. Run experiment
python3 run_with_skills.py --all

# 2. Analyze
python3 analyze_results_local.py

# 3. Include in report:
#    - semantic_drift_analysis_local.png (graphs)
#    - analysis_results_local.json (data)
#    - outputs/noise_X/ (agent outputs)
```

### **What to Submit**

- âœ… Code: `run_with_skills.py`, `analyze_results_local.py`
- âœ… Skills: `skills/` directory
- âœ… Results: `outputs/` directory
- âœ… Graph: `semantic_drift_analysis_local.png`
- âœ… Data: `analysis_results_local.json`
- âœ… Report: Your analysis document

---

## âœ¨ Summary

**3 Simple Steps:**
1. `python3 run_with_skills.py --all` - Run pipeline
2. `python3 analyze_results_local.py` - Analyze
3. `open semantic_drift_analysis_local.png` - View

**That's it!** Complete end-to-end execution via CLI. ðŸš€

